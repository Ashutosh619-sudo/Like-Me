{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BpGJFlG8sZbA"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OHZ3KwFbKuw8"
   },
   "outputs": [],
   "source": [
    "from string import printable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d9VVdFtNL4Zp"
   },
   "outputs": [],
   "source": [
    "def remove_emoji(df):\n",
    "  return df.applymap(lambda y: ''.join(filter(lambda x: x in printable, y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5ad0C3jxRDQG"
   },
   "outputs": [],
   "source": [
    "def json_to_df(path,other_person):\n",
    "  \n",
    "  sample_message = open(path)\n",
    "  \n",
    "  sample_message = json.load(sample_message)\n",
    "  sample_message = sample_message[\"messages\"]\n",
    "\n",
    "  new_sample = []\n",
    "  for m in sample_message:\n",
    "    if \"content\" in m.keys():\n",
    "      new_sample.append(m)\n",
    "  \n",
    "  pairs = []\n",
    "  message = []\n",
    "  for m in new_sample[::-1]:\n",
    "    if len(message) == 0 or len(message) == 2:\n",
    "      if m[\"sender_name\"] == other_person:\n",
    "        message = []\n",
    "        message.append(m[\"content\"])\n",
    "    elif len(message) == 1:\n",
    "      if m[\"sender_name\"] == other_person:\n",
    "        message[0] = message[0] + \" \" + m[\"content\"]\n",
    "      else:\n",
    "        message.append(m[\"content\"])\n",
    "    else:\n",
    "      if m[\"sender_name\"] == \"Ashutosh Singh\":\n",
    "        message[1] = message[1] + \" \" + m[\"content\"]\n",
    "\n",
    "    pairs.append(message)\n",
    "\n",
    "  new_pair = []\n",
    "  for pair in pairs:\n",
    "    if len(pair) == 2:\n",
    "      new_pair.append(pair)  \n",
    "\n",
    "  me = []\n",
    "  other = []\n",
    "\n",
    "  for pair in new_pair:\n",
    "    other.append(pair[0])\n",
    "    me.append(pair[1])\n",
    "\n",
    "  sample_df = pd.DataFrame()\n",
    "  sample_df[\"other\"] = np.array(other)\n",
    "  sample_df[\"me\"] = np.array(me)\n",
    "  sample_df = sample_df.drop_duplicates(keep=\"first\")\n",
    "\n",
    "  df = remove_emoji(sample_df)\n",
    "  return df                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "id": "9pRcfZcQjM3A",
    "outputId": "319fcd30-866d-45af-9ca6-713125c6fada"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ayush.zip\n",
      "   creating: ayush/\n",
      "  inflating: ayush/message_1.json    \n"
     ]
    }
   ],
   "source": [
    "!unzip ayush.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K7RS5m4uSnvL"
   },
   "outputs": [],
   "source": [
    "username1_df = json_to_df(\"Name/message_1.json\",\"Username\")\n",
    "username2_df = json_to_df(\"Name/message_1.json\",\"Username\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z_1RoCB6WTZ5"
   },
   "outputs": [],
   "source": [
    "username3_df = json_to_df(\"Name/message_1.json\",\"Username3\")\n",
    "username3_df = json_to_df(\"Name/message_1.json\",\"Username4\")\n",
    "username4_df = json_to_df(\"Name/message_1.json\",\"Username5\")\n",
    "username5_df = json_to_df(\"Name/message_1.json\",\"Username6\")\n",
    "username6_df = json_to_df(\"Name/message_1.json\",\"Username7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r9epvabnZC1N"
   },
   "outputs": [],
   "source": [
    "username7_df = json_to_df(\"Name/message_1.json\",\"Username8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3rnWAa30CPxE"
   },
   "outputs": [],
   "source": [
    "train_df = pd.concat([username1_df,username2_df,username3_df,username4_df,username5_df,username6_df,username7_df],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-nDtxXtSCf81"
   },
   "outputs": [],
   "source": [
    "train_df.drop(train_df[train_df[\"other\"]==\" \"].index,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-yxayagvFqQU"
   },
   "outputs": [],
   "source": [
    "train_df.drop(train_df[train_df[\"me\"]==\" \"].index,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "qdoKaeXnF0ij",
    "outputId": "e423d243-1c29-4a94-b960-683c30dbaf25"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 2)"
      ]
     },
     "execution_count": 276,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MhRFWUe1GJmb"
   },
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "31xOaBjMGyYv"
   },
   "outputs": [],
   "source": [
    "train_df[\"other\"] = train_df[\"other\"].apply(lambda x: normalizeString(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sZo4WaHGHVa1"
   },
   "outputs": [],
   "source": [
    "train_df[\"me\"] = train_df[\"me\"].apply(lambda x: normalizeString(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tiAf3S2FIISl"
   },
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DIW5-mzxJRc_"
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WzVNag1GJ8dS"
   },
   "outputs": [],
   "source": [
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9NnOOIXtKAAx"
   },
   "outputs": [],
   "source": [
    "def prepareData(pairs):\n",
    "    input_lang, output_lang = Lang(\"other\"),Lang(\"me\")\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IOXGmC2tKY5G"
   },
   "outputs": [],
   "source": [
    "pairs = train_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "id": "LykuwyZ_KtGP",
    "outputId": "4e170ef6-7733-4f93-d10e-d9518bc3d111"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 6000 sentence pairs\n",
      "Trimmed to 3472 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "other 3657\n",
      "me 2005\n"
     ]
    }
   ],
   "source": [
    "input_lang, output_lang, pairs = prepareData(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "uS9mHyGBL84l",
    "outputId": "2c9bce37-52f5-43c3-c9c4-0aee3a9e6a2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['kk gussa aarha h' 'chodh n be']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZUtjJ-INMEHP"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "driXTIH4Mn1B"
   },
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sxOm_TteMuzA"
   },
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7VGDdFyLNKtm"
   },
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uiBwhagZNa2r"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "etjQBmctNdMq"
   },
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y17eS6f8NxZ7"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-KRc6TzLN05U"
   },
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VxD2GNVuN5SB"
   },
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "lw8UVnllN7QC",
    "outputId": "837f9584-3d0f-478c-848a-50f0d0546982"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 53s (- 12m 25s) (5000 6%) 3.7082\n",
      "1m 42s (- 11m 6s) (10000 13%) 3.4322\n",
      "2m 32s (- 10m 11s) (15000 20%) 3.1157\n",
      "3m 23s (- 9m 20s) (20000 26%) 2.8152\n",
      "4m 16s (- 8m 33s) (25000 33%) 2.4791\n",
      "5m 11s (- 7m 46s) (30000 40%) 2.0934\n",
      "6m 6s (- 6m 58s) (35000 46%) 1.7638\n",
      "7m 1s (- 6m 8s) (40000 53%) 1.3684\n",
      "7m 58s (- 5m 19s) (45000 60%) 1.0777\n",
      "8m 55s (- 4m 27s) (50000 66%) 0.8172\n",
      "9m 54s (- 3m 36s) (55000 73%) 0.6790\n",
      "10m 52s (- 2m 43s) (60000 80%) 0.5137\n",
      "11m 50s (- 1m 49s) (65000 86%) 0.4166\n",
      "12m 48s (- 0m 54s) (70000 93%) 0.3221\n",
      "13m 47s (- 0m 0s) (75000 100%) 0.2794\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "trainIters(encoder1, attn_decoder1, 75000, print_every=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "WR6ATDlPOaVr",
    "outputId": "8e248247-c442-4efb-98a0-7764eb0875e6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 299,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 732
    },
    "id": "55RXzqoPPN4B",
    "outputId": "bf86bca6-8300-4d48-c3e2-96aa94514ae4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> aaj hi frnd banaaunga usko jaldii bol meko bheje\n",
      "= dher mt pagala\n",
      "< dher mt pagala <EOS>\n",
      "\n",
      "> jan gaye h rozz rozz ka h\n",
      "= ha\n",
      "< ha <EOS>\n",
      "\n",
      "> abe kyaa reh gyaa aaa\n",
      "= bs nikl gya hu\n",
      "< bs nikl gya hu <EOS>\n",
      "\n",
      "> ha ankit bola h ayega\n",
      "= acha\n",
      "< acha <EOS>\n",
      "\n",
      "> i am back\n",
      "= toh ka kru\n",
      "< toh ka kru <EOS>\n",
      "\n",
      "> matalabi\n",
      "= me bhi krta hu khaane me mdat\n",
      "< me bhi krta hu khaane me mdat <EOS>\n",
      "\n",
      "> sonali accept krrlii mera req .\n",
      "= mera nhi ki be\n",
      "< mera nhi ki be <EOS>\n",
      "\n",
      "> kyu maja nahi aata hai tumko dosto ke saath\n",
      "= nhi mere ko ab nhi aata\n",
      "< nhi mere ko ab nhi aata <EOS>\n",
      "\n",
      "> ha . .maan li . .ji\n",
      "= paper kaisa ja rha h\n",
      "< paper kaisa ja rha h <EOS>\n",
      "\n",
      "> ha . .ji . .\n",
      "= mst ladka h\n",
      "< mst ladka h <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder1, attn_decoder1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ke4V2TJqSkVN"
   },
   "outputs": [],
   "source": [
    "def evaluateinput(encoder, decoder,input):\n",
    "  output_words, attentions = evaluate(encoder, decoder, input)\n",
    "  output_sentence = ' '.join(output_words)\n",
    "  print(\"Input = \", input)\n",
    "  print('Output = ', output_sentence)\n",
    "  print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "id": "skRDZ9RiTTz4",
    "outputId": "3ca3033a-c803-4a1b-e103-26b8e34b4547"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input =  hii\n",
      "Output =  aur btao kya haal h <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateinput(encoder1,attn_decoder1,\"hii\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "id": "YQBxVe1uTf75",
    "outputId": "f78be303-d4d3-4c04-e973-7362707c0aa3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input =  sona mt be\n",
      "Output =  acha thik h <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateinput(encoder1,attn_decoder1,\"sona mt be\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "id": "866xEK-rxdSi",
    "outputId": "9c7fab25-1385-4d3e-b6ac-3941126b541c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input =  koi gf h\n",
      "Output =  ha <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateinput(encoder1,attn_decoder1,\"koi gf h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "id": "9-udfZAPxiCo",
    "outputId": "2d321ab9-406c-419a-bdf6-b6ebd04e0b3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input =  kya kr rha\n",
      "Output =  padh rhe the <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateinput(encoder1,attn_decoder1,\"kya kr rha\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "id": "p0mpMzMsxrvZ",
    "outputId": "05539bb5-01fc-483e-cb4d-e9b9700f211f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input =  padh liye\n",
      "Output =  nhi aaj mja lenge <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateinput(encoder1,attn_decoder1,\"padh liye\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "id": "8GZrwEcexuxL",
    "outputId": "0402b2c7-0006-4685-a42b-30f01ae0dd39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input =  chutiya ho kya\n",
      "Output =  virat kholi ka h n aaaa thuuu <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateinput(encoder1,attn_decoder1,\"chutiya ho kya\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "id": "VFSAnEmvx1M3",
    "outputId": "984fce9d-4cbb-4eeb-91a9-d484fdfe8e69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input =  kya ho rha\n",
      "Output =  kuch nhi yr <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateinput(encoder1,attn_decoder1,\"kya ho rha\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "id": "yaSiNKuQx9aW",
    "outputId": "73e4486c-8fc2-4ea8-cc8a-5797f3306988"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input =  kya haal h\n",
      "Output =  ka btaye <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateinput(encoder1,attn_decoder1,\"kya haal h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "id": "8eFjsCUtyEwZ",
    "outputId": "9f8a6e2f-66d1-4e3f-e090-ec8c2ec775d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input =  bc\n",
      "Output =  kya bol rhe ho bkchod <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateinput(encoder1,attn_decoder1,\"bc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OO5h0XjR4AmU"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "like me.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
